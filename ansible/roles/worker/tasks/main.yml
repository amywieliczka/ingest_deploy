---
# tasks file for provision_worker
- name: include vaulted passwords from vaulted.yml
  include_vars: vaulted.yml
- name: get correct urls for environment
  include_vars:  "main{{ name_suffix }}.yml"
- debug: var=couchdb_url
- debug: var=solr_url
- debug: var=redis_host
- name: install ssh private key for bitbucket
  template: src=id_rsa mode=600 dest=~/.ssh/id_rsa 
- name: install ssh pub key for bitbucket
  template: src=id_rsa.pub mode=600 dest=~/.ssh/id_rsa.pub 
- { include: install_packages.yml }
- name: make user ~/bin directory
  file: path=/home/{{ ansible_ssh_user}}/bin state=directory
- name: make virtualenv directory
  file: path={{ dir_venv }} state=directory
- name: pull ingest harvester code to local box
  git:
    repo: https://github.com/mredar/harvester.git
    dest: "{{ dir_code }}/harvester"
    update: yes
- name: pull dpla based code to local box
  git: 
    repo: git@bitbucket.org:mredar/dpla-ingestion.git
    dest: "{{ dir_code }}/dpla/ingestion"
    accept_hostkey: yes
    version: ucldc
    update: yes
- name: install akara and harvester dpla dependencies
  pip:
    state: present
    requirements: "{{ dir_code }}/dpla/ingestion/requirements.txt"
    executable: pip2.7
    virtualenv: "{{ dir_venv }}"
- name: put .boto in place for strict cert checking fix
# https://github.com/boto/boto/issues/2836
  copy: src=.boto dest=~/.boto mode=600
- name: install harvester code
  command: "{{ dir_venv }}/bin/python {{ dir_code }}/harvester/setup.py install"
  args:
    chdir: "{{ dir_code }}/harvester"
#  how do you keep dev, prod, stg separate.
#  with, vars per host.
- name: put run_solr_update in bin
  template:
      src: run_solr_update.sh.j2
      dest: ~/bin/run_solr_update.sh
      mode: 0755
################################################################################
#configure akara
################################################################################
- name: copy config file to akara dir???? configure & start akara
  template:
    src: akara.ini.j2
    dest: "{{ dir_code }}/dpla/ingestion/akara.ini"
# configure and start akara
- name: create akara.conf
  command: "{{ dir_venv }}/bin/python setup.py install"
  args:
    chdir: "{{ dir_code }}/dpla/ingestion"
- name: make akara run dir
  sudo: yes
  file:
    path: "{{ dir_akara_run }}"
    state: directory
    owner: "{{ ansible_ssh_user }}"
    group: "{{ ansible_ssh_user }}"
- name: setup akara run dir
  command: "{{ dir_venv}}/bin/akara -f {{ dir_code }}/dpla/ingestion/akara.conf setup"
  args:
    chdir:  "{{ dir_akara_run }}"
- name: run akara
  command: "{{ dir_venv}}/bin/akara -f {{ dir_code }}/dpla/ingestion/akara.conf start"
  args:
    chdir:  "{{ dir_akara_run }}"
    creates: "{{ dir_akara_run }}/logs/akara.pid"
################################################################################
#configure rq worker
################################################################################
- name: make rqworker run dir
  sudo: yes
  file:
    path: "{{ dir_rqworker_run }}"
    state: directory
    owner: "{{ ansible_ssh_user }}"
    group: "{{ ansible_ssh_user }}"
- name: make profiles dir
  file:
    path: "{{ dir_rqworker_run }}/profiles"
    state: directory
- name: make logs dir
  file:
    path: "{{ dir_rqworker_run }}/logs"
    state: directory
- name: create pynuxrc for the rqworker in working dir #this doesn't seem to work
  template:
    src: pynuxrc
    dest: "{{ dir_rqworker_run }}/.pynuxrc"
- name: create rqw-settings.py
  template:
    src: rqw-settings.py.j2
    dest: "{{ dir_rqworker_run }}/rqw-settings.py"
- name: put harvester-env in place
  template:
    src: harvester-env.j2
    dest: "{{ dir_rqworker_run}}/.harvester-env"
    mode: "0600"
- name: put start rqworker file in place
  sudo: yes
  template:
    src: start-rqworker.sh.j2
    dest: /usr/local/bin/start-rqworker.sh
    mode: "0777"
- name: put stop rqworker file in place
  sudo: yes
  template:
    src: stop-rqworker.sh.j2
    dest: /usr/local/bin/stop-rqworker.sh
    mode: "0777"
- name: halt.local to call stop rqworker in place
  sudo: yes
  template:
    src: halt.local.j2
    dest: /sbin/halt.local
    mode: "0777"
- name: start rqworker
  sudo: no
  shell: /usr/local/bin/start-rqworker.sh
  args:
    creates: "{{ dir_rqworker_run}}/rqworker.pid"
